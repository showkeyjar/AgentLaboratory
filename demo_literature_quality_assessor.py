"""
æ–‡çŒ®è´¨é‡è¯„ä¼°ç³»ç»Ÿæ¼”ç¤º

å±•ç¤ºè®ºæ–‡è´¨é‡è¯„ä¼°ã€ç­›é€‰å’ŒæŠ¥å‘Šç”ŸæˆåŠŸèƒ½
"""

import sys
sys.path.append('.')

from research_automation.core.literature_quality_assessor import (
    LiteratureQualityAssessor, Paper, QualityDimension
)
from research_automation.models.research_models import TopicAnalysis, ResearchType, ResearchComplexity


def demo_literature_quality_assessment():
    """æ¼”ç¤ºæ–‡çŒ®è´¨é‡è¯„ä¼°åŠŸèƒ½"""
    print("ğŸ“š æ–‡çŒ®è´¨é‡è¯„ä¼°ç³»ç»Ÿæ¼”ç¤º")
    print("=" * 50)
    
    # åˆå§‹åŒ–ç»„ä»¶
    config = {
        'quality_threshold': 0.6,
        'citation_weight': 0.3
    }
    
    assessor = LiteratureQualityAssessor(config=config)
    
    # åˆ›å»ºæµ‹è¯•è®ºæ–‡
    papers = create_test_papers()
    
    print(f"\nğŸ“‹ æµ‹è¯•è®ºæ–‡æ•°é‡: {len(papers)}")
    print("-" * 50)
    
    # æ¼”ç¤ºå•ç¯‡è®ºæ–‡è¯„ä¼°
    demo_single_paper_evaluation(assessor, papers)
    
    # æ¼”ç¤ºæ‰¹é‡è®ºæ–‡è¯„ä¼°
    demo_batch_evaluation(assessor, papers)
    
    # æ¼”ç¤ºé«˜è´¨é‡è®ºæ–‡ç­›é€‰
    demo_quality_filtering(assessor, papers)
    
    # æ¼”ç¤ºè´¨é‡è¯„ä¼°æŠ¥å‘Š
    demo_quality_report(assessor, papers)
    
    # æ¼”ç¤ºä¸Šä¸‹æ–‡ç›¸å…³è¯„ä¼°
    demo_context_aware_evaluation(assessor, papers)
    
    print(f"\nğŸ‰ æ¼”ç¤ºå®Œæˆ!")
    print("=" * 50)


def create_test_papers():
    """åˆ›å»ºæµ‹è¯•è®ºæ–‡"""
    papers = [
        Paper(
            title="A Novel Deep Learning Framework for Medical Image Analysis with Explainable AI",
            authors=["Dr. Sarah Johnson", "Prof. Michael Chen", "Dr. Emily Rodriguez"],
            abstract="This paper presents a comprehensive and innovative deep learning framework for medical image analysis that incorporates explainable AI techniques. We propose a novel convolutional neural network architecture that significantly outperforms existing methods on multiple medical imaging datasets. Extensive experiments demonstrate the effectiveness and robustness of our approach. Statistical analysis shows significant improvements with p-value < 0.001. The proposed method achieves state-of-the-art performance while providing interpretable results for clinical decision-making.",
            keywords=["deep learning", "medical imaging", "explainable AI", "CNN", "image analysis"],
            publication_year=2023,
            journal="Nature Medicine",
            citation_count=89,
            doi="10.1038/s41591-023-12345",
            venue_type="journal"
        ),
        Paper(
            title="Machine Learning Applications in Data Processing: A Comparative Study",
            authors=["Alice Brown", "Bob Wilson"],
            abstract="This study explores various machine learning applications in data processing tasks. We implement several popular algorithms including decision trees, random forests, and support vector machines. Results show moderate improvements over baseline methods. The evaluation is conducted on standard datasets with cross-validation. Further research is needed to optimize hyperparameters.",
            keywords=["machine learning", "data processing", "algorithms"],
            publication_year=2021,
            journal="IEEE Transactions on Data Engineering",
            citation_count=23,
            venue_type="journal"
        ),
        Paper(
            title="Preliminary Investigation of Some Methods",
            authors=["Unknown Author"],
            abstract="This is a preliminary study with limited scope and incomplete methodology. The results are inconclusive and require further investigation. Sample size is small and statistical significance is not achieved.",
            keywords=[],
            publication_year=2019,
            journal="Unknown Conference Proceedings",
            citation_count=3,
            venue_type="conference"
        ),
        Paper(
            title="Quantum Computing Algorithms for Optimization: A Comprehensive Survey",
            authors=["Prof. David Kim", "Dr. Lisa Zhang", "Dr. James Miller", "Dr. Anna Petrov"],
            abstract="This comprehensive survey reviews the current state of quantum computing algorithms for optimization problems. We systematically analyze various quantum optimization approaches including QAOA, VQE, and quantum annealing. The paper provides a thorough comparison of theoretical foundations and practical implementations. We identify key challenges and future research directions in quantum optimization. This work serves as a valuable reference for researchers entering the field.",
            keywords=["quantum computing", "optimization", "QAOA", "VQE", "quantum algorithms"],
            publication_year=2022,
            journal="Reviews of Modern Physics",
            citation_count=156,
            doi="10.1103/RevModPhys.94.015004",
            venue_type="journal"
        ),
        Paper(
            title="An Approach to Something",
            authors=["Student A"],
            abstract="We tried some things and got some results. The method is not clearly described. Results are presented without proper statistical analysis.",
            keywords=["approach", "method"],
            publication_year=2020,
            journal="Workshop Proceedings",
            citation_count=1,
            venue_type="workshop"
        )
    ]
    
    return papers


def demo_single_paper_evaluation(assessor, papers):
    """æ¼”ç¤ºå•ç¯‡è®ºæ–‡è¯„ä¼°"""
    print(f"\nğŸ” å•ç¯‡è®ºæ–‡è´¨é‡è¯„ä¼°æ¼”ç¤º")
    
    # é€‰æ‹©ç¬¬ä¸€ç¯‡è®ºæ–‡è¿›è¡Œè¯¦ç»†è¯„ä¼°
    paper = papers[0]
    print(f"\nğŸ“„ è¯„ä¼°è®ºæ–‡: {paper.title[:60]}...")
    print(f"   ä½œè€…: {', '.join(paper.authors[:2])}{'ç­‰' if len(paper.authors) > 2 else ''}")
    print(f"   æœŸåˆŠ: {paper.journal}")
    print(f"   å¹´ä»½: {paper.publication_year}")
    print(f"   å¼•ç”¨: {paper.citation_count}")
    
    # è¿›è¡Œè´¨é‡è¯„ä¼°
    quality_score = assessor.evaluate_paper_quality(paper)
    
    print(f"\nâœ… è¯„ä¼°ç»“æœ:")
    print(f"   ç»¼åˆåˆ†æ•°: {quality_score.overall_score:.2f}")
    print(f"   ç½®ä¿¡åº¦: {quality_score.confidence:.2f}")
    
    print(f"\nğŸ“Š å„ç»´åº¦åˆ†æ•°:")
    for dimension, score in quality_score.dimension_scores.items():
        print(f"   {dimension.value}: {score:.2f}")
    
    print(f"\nğŸ’¡ è¯„ä¼°ç†ç”±:")
    for reason in quality_score.reasoning[:5]:
        print(f"   â€¢ {reason}")
    
    print(f"\nğŸ¯ å»ºè®®:")
    for recommendation in quality_score.recommendations[:3]:
        print(f"   â€¢ {recommendation}")


def demo_batch_evaluation(assessor, papers):
    """æ¼”ç¤ºæ‰¹é‡è®ºæ–‡è¯„ä¼°"""
    print(f"\nğŸ“Š æ‰¹é‡è®ºæ–‡è¯„ä¼°æ¼”ç¤º")
    
    # æ‰¹é‡è¯„ä¼°æ‰€æœ‰è®ºæ–‡
    quality_scores = assessor.batch_evaluate_papers(papers)
    
    print(f"\nğŸ“ˆ è¯„ä¼°ç»“æœæ±‡æ€»:")
    for i, (paper, score) in enumerate(zip(papers, quality_scores)):
        print(f"   {i+1}. {paper.title[:40]}...")
        print(f"      ç»¼åˆåˆ†æ•°: {score.overall_score:.2f}")
        print(f"      ç½®ä¿¡åº¦: {score.confidence:.2f}")
        
        # æ˜¾ç¤ºè´¨é‡ç­‰çº§
        if score.overall_score >= 0.8:
            quality_level = "ä¼˜ç§€"
        elif score.overall_score >= 0.6:
            quality_level = "è‰¯å¥½"
        elif score.overall_score >= 0.4:
            quality_level = "ä¸€èˆ¬"
        else:
            quality_level = "è¾ƒå·®"
        
        print(f"      è´¨é‡ç­‰çº§: {quality_level}")
        print()


def demo_quality_filtering(assessor, papers):
    """æ¼”ç¤ºé«˜è´¨é‡è®ºæ–‡ç­›é€‰"""
    print(f"\nğŸ” é«˜è´¨é‡è®ºæ–‡ç­›é€‰æ¼”ç¤º")
    
    # è®¾ç½®ä¸åŒçš„è´¨é‡é˜ˆå€¼è¿›è¡Œç­›é€‰
    thresholds = [0.8, 0.6, 0.4]
    
    for threshold in thresholds:
        print(f"\n   è´¨é‡é˜ˆå€¼: {threshold}")
        
        high_quality_papers = assessor.filter_high_quality_papers(
            papers, min_score=threshold
        )
        
        print(f"   ç­›é€‰ç»“æœ: {len(papers)}ç¯‡è®ºæ–‡ä¸­ç­›é€‰å‡º{len(high_quality_papers)}ç¯‡")
        
        if high_quality_papers:
            print(f"   é«˜è´¨é‡è®ºæ–‡:")
            for i, (paper, score) in enumerate(high_quality_papers[:3], 1):
                print(f"      {i}. {paper.title[:50]}...")
                print(f"         åˆ†æ•°: {score.overall_score:.2f}")
        else:
            print(f"   æ— è®ºæ–‡è¾¾åˆ°è¯¥è´¨é‡é˜ˆå€¼")


def demo_quality_report(assessor, papers):
    """æ¼”ç¤ºè´¨é‡è¯„ä¼°æŠ¥å‘Š"""
    print(f"\nğŸ“‹ è´¨é‡è¯„ä¼°æŠ¥å‘Šæ¼”ç¤º")
    
    # æ‰¹é‡è¯„ä¼°
    quality_scores = assessor.batch_evaluate_papers(papers)
    
    # ç”Ÿæˆè´¨é‡æŠ¥å‘Š
    report = assessor.generate_quality_report(papers, quality_scores)
    
    print(f"\nğŸ“Š æŠ¥å‘Šæ‘˜è¦:")
    summary = report['summary']
    print(f"   æ€»è®ºæ–‡æ•°: {summary['total_papers']}")
    print(f"   å¹³å‡è´¨é‡: {summary['average_quality']:.2f}")
    print(f"   é«˜è´¨é‡è®ºæ–‡: {summary['high_quality_count']}ç¯‡")
    print(f"   ä¸­ç­‰è´¨é‡è®ºæ–‡: {summary['medium_quality_count']}ç¯‡")
    print(f"   ä½è´¨é‡è®ºæ–‡: {summary['low_quality_count']}ç¯‡")
    
    print(f"\nğŸ“ˆ ç»´åº¦åˆ†æ:")
    dimension_analysis = report['dimension_analysis']
    for dimension, stats in dimension_analysis.items():
        print(f"   {dimension}:")
        print(f"      å¹³å‡åˆ†: {stats['average']:.2f}")
        print(f"      æœ€é«˜åˆ†: {stats['max']:.2f}")
        print(f"      æœ€ä½åˆ†: {stats['min']:.2f}")
    
    print(f"\nğŸ† é¡¶çº§è®ºæ–‡:")
    for i, top_paper in enumerate(report['top_papers'][:3], 1):
        print(f"   {i}. {top_paper['title'][:50]}...")
        print(f"      åˆ†æ•°: {top_paper['overall_score']:.2f}")
        print(f"      ç½®ä¿¡åº¦: {top_paper['confidence']:.2f}")
    
    print(f"\nğŸ’¡ æ€»ä½“å»ºè®®:")
    for recommendation in report['recommendations']:
        print(f"   â€¢ {recommendation}")


def demo_context_aware_evaluation(assessor, papers):
    """æ¼”ç¤ºä¸Šä¸‹æ–‡ç›¸å…³è¯„ä¼°"""
    print(f"\nğŸ¯ ä¸Šä¸‹æ–‡ç›¸å…³è¯„ä¼°æ¼”ç¤º")
    
    # åˆ›å»ºæ¨¡æ‹Ÿä¸»é¢˜åˆ†æä¸Šä¸‹æ–‡
    context = type('TopicAnalysis', (), {
        'keywords': ['deep learning', 'medical imaging', 'neural network', 'AI'],
        'research_type': ResearchType.EXPERIMENTAL,
        'complexity_level': ResearchComplexity.HIGH
    })()
    
    print(f"\nğŸ”¬ ç ”ç©¶ä¸Šä¸‹æ–‡:")
    print(f"   å…³é”®è¯: {', '.join(context.keywords)}")
    print(f"   ç ”ç©¶ç±»å‹: {context.research_type.value}")
    print(f"   å¤æ‚åº¦: {context.complexity_level.value}")
    
    # å¯¹æ¯”æœ‰æ— ä¸Šä¸‹æ–‡çš„è¯„ä¼°ç»“æœ
    paper = papers[0]  # é€‰æ‹©ç¬¬ä¸€ç¯‡è®ºæ–‡
    
    print(f"\nğŸ“„ æµ‹è¯•è®ºæ–‡: {paper.title[:50]}...")
    
    # æ— ä¸Šä¸‹æ–‡è¯„ä¼°
    score_without_context = assessor.evaluate_paper_quality(paper)
    
    # æœ‰ä¸Šä¸‹æ–‡è¯„ä¼°
    score_with_context = assessor.evaluate_paper_quality(paper, context)
    
    print(f"\nğŸ“Š è¯„ä¼°ç»“æœå¯¹æ¯”:")
    print(f"   æ— ä¸Šä¸‹æ–‡:")
    print(f"      ç»¼åˆåˆ†æ•°: {score_without_context.overall_score:.2f}")
    print(f"      ç›¸å…³æ€§åˆ†æ•°: {score_without_context.dimension_scores[QualityDimension.RELEVANCE]:.2f}")
    
    print(f"   æœ‰ä¸Šä¸‹æ–‡:")
    print(f"      ç»¼åˆåˆ†æ•°: {score_with_context.overall_score:.2f}")
    print(f"      ç›¸å…³æ€§åˆ†æ•°: {score_with_context.dimension_scores[QualityDimension.RELEVANCE]:.2f}")
    
    # åˆ†æå·®å¼‚
    score_diff = score_with_context.overall_score - score_without_context.overall_score
    relevance_diff = (score_with_context.dimension_scores[QualityDimension.RELEVANCE] - 
                     score_without_context.dimension_scores[QualityDimension.RELEVANCE])
    
    print(f"\nğŸ“ˆ å·®å¼‚åˆ†æ:")
    print(f"   ç»¼åˆåˆ†æ•°æå‡: {score_diff:+.2f}")
    print(f"   ç›¸å…³æ€§åˆ†æ•°æå‡: {relevance_diff:+.2f}")
    
    if score_diff > 0:
        print(f"   ç»“è®º: ä¸Šä¸‹æ–‡ä¿¡æ¯æé«˜äº†è®ºæ–‡çš„è´¨é‡è¯„åˆ†")
    else:
        print(f"   ç»“è®º: ä¸Šä¸‹æ–‡ä¿¡æ¯å¯¹è¯¥è®ºæ–‡è¯„åˆ†å½±å“è¾ƒå°")


def demo_quality_dimensions():
    """æ¼”ç¤ºè´¨é‡ç»´åº¦åˆ†æ"""
    print(f"\nğŸ” è´¨é‡ç»´åº¦è¯¦ç»†åˆ†ææ¼”ç¤º")
    
    config = {'quality_threshold': 0.6, 'citation_weight': 0.3}
    assessor = LiteratureQualityAssessor(config=config)
    
    # åˆ›å»ºä¸€ç¯‡é«˜è´¨é‡è®ºæ–‡è¿›è¡Œè¯¦ç»†åˆ†æ
    paper = Paper(
        title="Breakthrough Advances in Quantum Machine Learning: A Comprehensive Framework",
        authors=["Prof. Alice Quantum", "Dr. Bob Neural", "Dr. Carol Computing"],
        abstract="This groundbreaking research presents a novel and comprehensive framework for quantum machine learning that revolutionizes the field. Our innovative approach combines quantum computing principles with advanced machine learning techniques, achieving unprecedented performance improvements. Extensive experimental validation on multiple datasets demonstrates significant statistical improvements (p < 0.001). The methodology is rigorously designed with proper controls and comprehensive evaluation metrics.",
        keywords=["quantum computing", "machine learning", "quantum algorithms", "optimization"],
        publication_year=2023,
        journal="Nature",
        citation_count=234,
        doi="10.1038/nature12345",
        venue_type="journal"
    )
    
    print(f"\nğŸ“„ åˆ†æè®ºæ–‡: {paper.title}")
    
    # è¯¦ç»†è¯„ä¼°
    quality_score = assessor.evaluate_paper_quality(paper)
    
    print(f"\nğŸ“Š è¯¦ç»†ç»´åº¦åˆ†æ:")
    
    dimension_names = {
        QualityDimension.RELEVANCE: "ç›¸å…³æ€§",
        QualityDimension.NOVELTY: "æ–°é¢–æ€§", 
        QualityDimension.METHODOLOGY: "æ–¹æ³•è®º",
        QualityDimension.IMPACT: "å½±å“åŠ›",
        QualityDimension.CREDIBILITY: "å¯ä¿¡åº¦",
        QualityDimension.CLARITY: "æ¸…æ™°åº¦"
    }
    
    for dimension, score in quality_score.dimension_scores.items():
        name = dimension_names.get(dimension, dimension.value)
        weight = assessor.dimension_weights[dimension]
        
        # ç”Ÿæˆè¯„åˆ†æ¡å½¢å›¾
        bar_length = int(score * 20)
        bar = "â–ˆ" * bar_length + "â–‘" * (20 - bar_length)
        
        print(f"   {name:8} [{bar}] {score:.2f} (æƒé‡: {weight:.1%})")
    
    print(f"\nğŸ¯ ç»¼åˆè¯„ä¼°:")
    print(f"   ç»¼åˆåˆ†æ•°: {quality_score.overall_score:.2f}")
    print(f"   ç½®ä¿¡åº¦: {quality_score.confidence:.2f}")
    
    # è´¨é‡ç­‰çº§åˆ¤å®š
    if quality_score.overall_score >= 0.9:
        level = "å“è¶Š"
        emoji = "ğŸŒŸ"
    elif quality_score.overall_score >= 0.8:
        level = "ä¼˜ç§€"
        emoji = "â­"
    elif quality_score.overall_score >= 0.7:
        level = "è‰¯å¥½"
        emoji = "ğŸ‘"
    elif quality_score.overall_score >= 0.6:
        level = "åˆæ ¼"
        emoji = "âœ…"
    else:
        level = "éœ€æ”¹è¿›"
        emoji = "âš ï¸"
    
    print(f"   è´¨é‡ç­‰çº§: {emoji} {level}")


if __name__ == "__main__":
    # è¿è¡Œä¸»æ¼”ç¤º
    demo_literature_quality_assessment()
    
    # è¿è¡Œç»´åº¦åˆ†ææ¼”ç¤º
    demo_quality_dimensions()