"""
æµ‹è¯•ç ”ç©¶æ–¹å‘å»ºè®®ç³»ç»Ÿ

éªŒè¯ç ”ç©¶æ–¹å‘å»ºè®®åŠŸèƒ½çš„å®Œæ•´æ€§å’Œå‡†ç¡®æ€§
"""

import sys
import json
from typing import Dict, Any

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append('.')

from research_automation.core.research_planner import ResearchPlannerComponent


def test_direction_recommendation_system():
    """æµ‹è¯•ç ”ç©¶æ–¹å‘å»ºè®®ç³»ç»Ÿ"""
    print("=== æµ‹è¯•ç ”ç©¶æ–¹å‘å»ºè®®ç³»ç»Ÿ ===\n")
    
    # åˆå§‹åŒ–ç»„ä»¶
    config = {
        'llm_model': 'test_model',
        'max_analysis_time': 300
    }
    
    planner = ResearchPlannerComponent(config=config)
    
    # æµ‹è¯•æ¡ˆä¾‹
    test_cases = [
        {
            "name": "AIåŒ»ç–—åº”ç”¨ç ”ç©¶",
            "topic": "Artificial intelligence for healthcare applications",
            "context": {
                'user_experience': 'intermediate',
                'available_resources': 'moderate',
                'time_constraint': '6_months',
                'research_goal': 'Develop AI solutions for medical diagnosis'
            }
        },
        {
            "name": "é‡å­è®¡ç®—ç®—æ³•ä¼˜åŒ–",
            "topic": "Quantum computing algorithms optimization",
            "context": {
                'user_experience': 'advanced',
                'available_resources': 'abundant',
                'time_constraint': '12_months'
            }
        },
        {
            "name": "æ·±åº¦å­¦ä¹ å›¾åƒè¯†åˆ«",
            "topic": "æ·±åº¦å­¦ä¹ åœ¨å›¾åƒè¯†åˆ«ä¸­çš„åº”ç”¨",
            "context": {
                'user_experience': 'beginner',
                'available_resources': 'limited',
                'time_constraint': '3_months'
            }
        }
    ]
    
    # æ‰§è¡Œæµ‹è¯•
    for i, test_case in enumerate(test_cases, 1):
        print(f"\n{'='*60}")
        print(f"æµ‹è¯•æ¡ˆä¾‹ {i}: {test_case['name']}")
        print(f"{'='*60}")
        
        try:
            # ç”Ÿæˆç ”ç©¶æ–¹å‘å»ºè®®
            result = planner.generate_research_directions(
                test_case['topic'], 
                test_case['context']
            )
            
            # æ˜¾ç¤ºç»“æœæ‘˜è¦
            display_test_results(result, test_case['name'])
            
            # ä¿å­˜è¯¦ç»†ç»“æœ
            save_test_results(result, f"test_result_{i}_{test_case['name']}.json")
            
        except Exception as e:
            print(f"âŒ æµ‹è¯•å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
    
    print(f"\n{'='*60}")
    print("æµ‹è¯•å®Œæˆ")
    print(f"{'='*60}")


def display_test_results(result: Dict[str, Any], test_name: str):
    """æ˜¾ç¤ºæµ‹è¯•ç»“æœæ‘˜è¦"""
    if not result:
        print("âŒ æœªç”Ÿæˆæœ‰æ•ˆç»“æœ")
        return
    
    print(f"âœ… {test_name} - æµ‹è¯•æˆåŠŸ")
    
    # ä¸»é¢˜åˆ†ææ‘˜è¦
    analysis = result.get('topic_analysis')
    if analysis:
        print(f"\nğŸ“Š ä¸»é¢˜åˆ†æ:")
        print(f"   å¤æ‚åº¦: {analysis.complexity_level.value} ({analysis.complexity_score:.2f})")
        print(f"   ç±»å‹: {analysis.research_type.value}")
        print(f"   æ—¶é•¿: {analysis.estimated_duration}å¤©")
        print(f"   æˆåŠŸç‡: {analysis.success_probability:.1%}")
    
    # ç ”ç©¶æ–¹å‘æ‘˜è¦
    directions = result.get('research_directions', {})
    total_directions = sum(len(dirs) for dirs in directions.values())
    print(f"\nğŸ¯ ç ”ç©¶æ–¹å‘: {len(directions)}ä¸ªç±»åˆ«, {total_directions}ä¸ªæ–¹å‘")
    
    for category, direction_list in directions.items():
        if direction_list:
            print(f"   {category}: {len(direction_list)}ä¸ª")
    
    # ä¸ªæ€§åŒ–æ¨èæ‘˜è¦
    recommendations = result.get('personalized_recommendations', {})
    top_recs = recommendations.get('top_recommendations', [])
    if top_recs:
        print(f"\nâ­ é¡¶çº§æ¨è:")
        for i, rec in enumerate(top_recs[:3], 1):
            score = rec.get('personalized_score', 0)
            print(f"   {i}. {rec['title']} (è¯„åˆ†: {score:.2f})")
    
    # ç»éªŒå’Œèµ„æºåŒ¹é…
    exp_match = recommendations.get('experience_match', {})
    res_align = recommendations.get('resource_alignment', {})
    
    if exp_match:
        print(f"\nğŸ“ˆ ç»éªŒåŒ¹é…: {exp_match.get('match_score', 0):.1%}")
    if res_align:
        print(f"ğŸ’° èµ„æºå¯¹é½: {res_align.get('alignment_score', 0):.1%}")
    
    # é€‰æ‹©æŒ‡å¯¼æ‘˜è¦
    guidance = result.get('selection_guidance', {})
    criteria = guidance.get('selection_criteria', [])
    if criteria:
        print(f"\nğŸ§­ é€‰æ‹©æ ‡å‡†: {len(criteria)}ä¸ª")
    
    print()


def save_test_results(result: Dict[str, Any], filename: str):
    """ä¿å­˜æµ‹è¯•ç»“æœåˆ°æ–‡ä»¶"""
    try:
        # è½¬æ¢ä¸ºå¯åºåˆ—åŒ–æ ¼å¼
        serializable_result = make_serializable(result)
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(serializable_result, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ° {filename}")
        
    except Exception as e:
        print(f"âš ï¸  ä¿å­˜æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")


def make_serializable(obj):
    """å°†å¯¹è±¡è½¬æ¢ä¸ºå¯åºåˆ—åŒ–æ ¼å¼"""
    if hasattr(obj, '__dict__'):
        # å¤„ç†è‡ªå®šä¹‰å¯¹è±¡
        result = {}
        for key, value in obj.__dict__.items():
            if not key.startswith('_'):  # è·³è¿‡ç§æœ‰å±æ€§
                result[key] = make_serializable(value)
        return result
    elif isinstance(obj, dict):
        return {key: make_serializable(value) for key, value in obj.items()}
    elif isinstance(obj, list):
        return [make_serializable(item) for item in obj]
    elif hasattr(obj, 'value'):  # å¤„ç†æšä¸¾ç±»å‹
        return obj.value
    else:
        return obj


def test_individual_components():
    """æµ‹è¯•å„ä¸ªç»„ä»¶åŠŸèƒ½"""
    print("\n=== æµ‹è¯•å„ä¸ªç»„ä»¶åŠŸèƒ½ ===\n")
    
    config = {
        'llm_model': 'test_model',
        'max_analysis_time': 300
    }
    
    planner = ResearchPlannerComponent(config=config)
    
    # æµ‹è¯•ä¸»é¢˜åˆ†æ
    print("1. æµ‹è¯•ä¸»é¢˜åˆ†æåŠŸèƒ½...")
    try:
        topic = "Machine learning for natural language processing"
        analysis = planner.analyze_topic(topic)
        
        print(f"âœ… ä¸»é¢˜åˆ†ææˆåŠŸ")
        print(f"   ä¸»é¢˜: {analysis.topic}")
        print(f"   å¤æ‚åº¦: {analysis.complexity_level.value}")
        print(f"   å…³é”®è¯æ•°é‡: {len(analysis.keywords)}")
        print(f"   ç›¸å…³é¢†åŸŸ: {len(analysis.related_fields)}")
        
    except Exception as e:
        print(f"âŒ ä¸»é¢˜åˆ†æå¤±è´¥: {str(e)}")
    
    # æµ‹è¯•ç ”ç©¶è®¡åˆ’ç”Ÿæˆ
    print("\n2. æµ‹è¯•ç ”ç©¶è®¡åˆ’ç”Ÿæˆ...")
    try:
        if 'analysis' in locals():
            plan = planner.generate_research_plan(analysis)
            
            print(f"âœ… ç ”ç©¶è®¡åˆ’ç”ŸæˆæˆåŠŸ")
            print(f"   æ—¶é—´çº¿: {len(plan.timeline)}ä¸ªé‡Œç¨‹ç¢‘")
            print(f"   ç ”ç©¶è·¯å¾„: {len(plan.research_paths)}æ¡")
            print(f"   æˆåŠŸæŒ‡æ ‡: {len(plan.success_metrics)}ä¸ª")
        
    except Exception as e:
        print(f"âŒ ç ”ç©¶è®¡åˆ’ç”Ÿæˆå¤±è´¥: {str(e)}")
    
    print("\nç»„ä»¶æµ‹è¯•å®Œæˆ")


if __name__ == "__main__":
    # è¿è¡Œä¸»è¦æµ‹è¯•
    test_direction_recommendation_system()
    
    # è¿è¡Œç»„ä»¶æµ‹è¯•
    test_individual_components()
    
    print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆ!")