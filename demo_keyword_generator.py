"""
æ™ºèƒ½å…³é”®è¯ç”Ÿæˆå™¨æ¼”ç¤º

å±•ç¤ºå…³é”®è¯æå–ã€æ‰©å±•å’Œæœç´¢ç­–ç•¥ç”ŸæˆåŠŸèƒ½
"""

import sys
sys.path.append('.')

from research_automation.core.keyword_generator import KeywordGeneratorComponent
from research_automation.models.research_models import ResearchType, ResearchComplexity


def demo_keyword_generation():
    """æ¼”ç¤ºå…³é”®è¯ç”ŸæˆåŠŸèƒ½"""
    print("ğŸ” æ™ºèƒ½å…³é”®è¯ç”Ÿæˆå™¨æ¼”ç¤º")
    print("=" * 50)
    
    # åˆå§‹åŒ–ç»„ä»¶
    config = {
        'max_keywords': 15,
        'similarity_threshold': 0.6
    }
    
    generator = KeywordGeneratorComponent(config=config)
    
    # æ¼”ç¤ºæ¡ˆä¾‹
    test_cases = [
        {
            "name": "æœºå™¨å­¦ä¹ åº”ç”¨",
            "topic": "Machine learning applications in natural language processing",
            "description": "ç»å…¸çš„æœºå™¨å­¦ä¹ ä¸»é¢˜"
        },
        {
            "name": "é‡å­è®¡ç®—ç ”ç©¶",
            "topic": "Quantum computing algorithms for optimization problems",
            "description": "å‰æ²¿çš„é‡å­è®¡ç®—ä¸»é¢˜"
        },
        {
            "name": "åŒ»ç–—AIåº”ç”¨",
            "topic": "Deep learning approaches for medical image analysis and diagnosis",
            "description": "è·¨å­¦ç§‘çš„åŒ»ç–—AIä¸»é¢˜"
        }
    ]
    
    for i, case in enumerate(test_cases, 1):
        print(f"\nğŸ“‹ æ¡ˆä¾‹ {i}: {case['name']}")
        print(f"ä¸»é¢˜: {case['topic']}")
        print(f"æè¿°: {case['description']}")
        print("-" * 50)
        
        try:
            # ç”Ÿæˆå…³é”®è¯åˆ†æ
            result = generator.generate_keywords(case['topic'])
            
            # æ˜¾ç¤ºç»“æœ
            display_keyword_analysis(result)
            
            # æ¼”ç¤ºæœç´¢æŸ¥è¯¢ä¼˜åŒ–
            demo_search_optimization(generator, result.primary_keywords[:3])
            
        except Exception as e:
            print(f"âŒ ç”Ÿæˆå¤±è´¥: {str(e)}")
    
    # æ¼”ç¤ºä¸Šä¸‹æ–‡æ‰©å±•
    demo_context_expansion(generator)
    
    print(f"\nğŸ‰ æ¼”ç¤ºå®Œæˆ!")
    print("=" * 50)


def display_keyword_analysis(result):
    """æ˜¾ç¤ºå…³é”®è¯åˆ†æç»“æœ"""
    print(f"\nâœ… å…³é”®è¯åˆ†æå®Œæˆ")
    
    # ä¸»è¦å…³é”®è¯
    if result.primary_keywords:
        print(f"\nğŸ¯ ä¸»è¦å…³é”®è¯ ({len(result.primary_keywords)}ä¸ª):")
        for i, keyword in enumerate(result.primary_keywords[:8], 1):
            relevance = result.relevance_scores.get(keyword, 0)
            print(f"   {i}. {keyword} (ç›¸å…³æ€§: {relevance:.2f})")
    
    # æ¬¡è¦å…³é”®è¯
    if result.secondary_keywords:
        print(f"\nğŸ”„ æ¬¡è¦å…³é”®è¯ ({len(result.secondary_keywords)}ä¸ª):")
        for keyword in result.secondary_keywords[:5]:
            print(f"   â€¢ {keyword}")
    
    # é¢†åŸŸå…³é”®è¯
    if result.domain_keywords:
        print(f"\nğŸ·ï¸  é¢†åŸŸå…³é”®è¯ ({len(result.domain_keywords)}ä¸ª):")
        for keyword in result.domain_keywords[:5]:
            print(f"   â€¢ {keyword}")
    
    # æ–¹æ³•å…³é”®è¯
    if result.method_keywords:
        print(f"\nâš™ï¸  æ–¹æ³•å…³é”®è¯ ({len(result.method_keywords)}ä¸ª):")
        for keyword in result.method_keywords[:5]:
            print(f"   â€¢ {keyword}")
    
    # æ‰©å±•å…³é”®è¯
    if result.expanded_keywords:
        print(f"\nğŸ“ˆ æ‰©å±•å…³é”®è¯ ({len(result.expanded_keywords)}ä¸ª):")
        for keyword in result.expanded_keywords[:5]:
            print(f"   â€¢ {keyword}")
    
    # å…³é”®è¯ç»„åˆ
    if result.keyword_combinations:
        print(f"\nğŸ”— å…³é”®è¯ç»„åˆ ({len(result.keyword_combinations)}ä¸ª):")
        for combo in result.keyword_combinations[:3]:
            print(f"   â€¢ {combo}")
    
    # æœç´¢ç­–ç•¥
    if result.search_strategies:
        print(f"\nğŸ¯ æœç´¢ç­–ç•¥ ({len(result.search_strategies)}ä¸ª):")
        for i, strategy in enumerate(result.search_strategies[:3], 1):
            print(f"   {i}. {strategy['name']}")
            print(f"      æè¿°: {strategy['description']}")
            print(f"      æŸ¥è¯¢: {strategy['search_query']}")
            print(f"      é¢„æœŸç»“æœ: {strategy.get('expected_results', 'N/A')}")
            print()


def demo_search_optimization(generator, keywords):
    """æ¼”ç¤ºæœç´¢æŸ¥è¯¢ä¼˜åŒ–"""
    print(f"\nğŸ”§ æœç´¢æŸ¥è¯¢ä¼˜åŒ–æ¼”ç¤º")
    
    # ä¸åŒçš„æœç´¢ä¸Šä¸‹æ–‡
    contexts = [
        {
            'name': 'å¹¿æ³›æœç´¢',
            'context': {'search_type': 'broad'},
        },
        {
            'name': 'ç²¾ç¡®æœç´¢',
            'context': {'search_type': 'precise'},
        },
        {
            'name': 'å¹³è¡¡æœç´¢',
            'context': {'search_type': 'balanced', 'time_filter': '2020-2023'},
        }
    ]
    
    for ctx in contexts:
        try:
            query = generator.optimize_search_query(keywords, ctx['context'])
            print(f"   {ctx['name']}: {query}")
        except Exception as e:
            print(f"   {ctx['name']}: ä¼˜åŒ–å¤±è´¥ - {str(e)}")


def demo_context_expansion(generator):
    """æ¼”ç¤ºä¸Šä¸‹æ–‡å…³é”®è¯æ‰©å±•"""
    print(f"\nğŸŒŸ ä¸Šä¸‹æ–‡å…³é”®è¯æ‰©å±•æ¼”ç¤º")
    
    # æ¨¡æ‹Ÿä¸»é¢˜åˆ†æç»“æœ
    class MockTopicAnalysis:
        def __init__(self, research_type, complexity_level, related_fields):
            self.research_type = research_type
            self.complexity_level = complexity_level
            self.related_fields = related_fields
    
    # æµ‹è¯•æ¡ˆä¾‹
    base_keywords = ['machine learning', 'classification']
    
    contexts = [
        {
            'name': 'å®éªŒç ”ç©¶',
            'analysis': MockTopicAnalysis(
                ResearchType.EXPERIMENTAL,
                ResearchComplexity.MEDIUM,
                ['Computer Science']
            )
        },
        {
            'name': 'ç†è®ºç ”ç©¶',
            'analysis': MockTopicAnalysis(
                ResearchType.THEORETICAL,
                ResearchComplexity.HIGH,
                ['Mathematics', 'Computer Science']
            )
        },
        {
            'name': 'è°ƒç ”ç ”ç©¶',
            'analysis': MockTopicAnalysis(
                ResearchType.SURVEY,
                ResearchComplexity.LOW,
                ['Computer Science']
            )
        }
    ]
    
    for ctx in contexts:
        try:
            expanded = generator.expand_keywords_with_context(
                base_keywords, ctx['analysis']
            )
            
            new_keywords = [kw for kw in expanded if kw not in base_keywords]
            
            print(f"\n   {ctx['name']}:")
            print(f"      åŸå§‹å…³é”®è¯: {', '.join(base_keywords)}")
            print(f"      æ–°å¢å…³é”®è¯: {', '.join(new_keywords[:5])}")
            print(f"      æ€»è®¡: {len(expanded)}ä¸ªå…³é”®è¯")
            
        except Exception as e:
            print(f"   {ctx['name']}: æ‰©å±•å¤±è´¥ - {str(e)}")


def demo_keyword_quality_analysis():
    """æ¼”ç¤ºå…³é”®è¯è´¨é‡åˆ†æ"""
    print(f"\nğŸ“Š å…³é”®è¯è´¨é‡åˆ†ææ¼”ç¤º")
    
    config = {
        'max_keywords': 10,
        'similarity_threshold': 0.5
    }
    
    generator = KeywordGeneratorComponent(config=config)
    
    # æµ‹è¯•ä¸åŒè´¨é‡çš„ä¸»é¢˜
    topics = [
        {
            'name': 'é«˜è´¨é‡ä¸»é¢˜',
            'topic': 'Deep learning neural networks for computer vision image recognition',
            'expected_quality': 'high'
        },
        {
            'name': 'ä¸­ç­‰è´¨é‡ä¸»é¢˜',
            'topic': 'Machine learning applications',
            'expected_quality': 'medium'
        },
        {
            'name': 'ä½è´¨é‡ä¸»é¢˜',
            'topic': 'Some research about things',
            'expected_quality': 'low'
        }
    ]
    
    for topic_info in topics:
        print(f"\n   {topic_info['name']}: {topic_info['topic']}")
        
        try:
            result = generator.generate_keywords(topic_info['topic'])
            
            # è®¡ç®—è´¨é‡æŒ‡æ ‡
            avg_relevance = sum(result.relevance_scores.values()) / len(result.relevance_scores) if result.relevance_scores else 0
            keyword_diversity = len(set(result.primary_keywords + result.secondary_keywords + result.domain_keywords))
            strategy_count = len(result.search_strategies)
            
            print(f"      å¹³å‡ç›¸å…³æ€§: {avg_relevance:.2f}")
            print(f"      å…³é”®è¯å¤šæ ·æ€§: {keyword_diversity}")
            print(f"      æœç´¢ç­–ç•¥æ•°: {strategy_count}")
            
            # è´¨é‡è¯„ä¼°
            if avg_relevance > 0.7 and keyword_diversity > 15:
                quality = "é«˜"
            elif avg_relevance > 0.5 and keyword_diversity > 10:
                quality = "ä¸­"
            else:
                quality = "ä½"
            
            print(f"      è´¨é‡è¯„ä¼°: {quality}")
            
        except Exception as e:
            print(f"      åˆ†æå¤±è´¥: {str(e)}")


if __name__ == "__main__":
    # è¿è¡Œä¸»æ¼”ç¤º
    demo_keyword_generation()
    
    # è¿è¡Œè´¨é‡åˆ†ææ¼”ç¤º
    demo_keyword_quality_analysis()